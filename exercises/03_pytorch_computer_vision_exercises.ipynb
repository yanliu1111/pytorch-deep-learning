{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_pytorch_computer_vision_exercises.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yanliu1111/pytorch-deep-learning/blob/main/exercises/03_pytorch_computer_vision_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. PyTorch Computer Vision Exercises\n",
        "\n",
        "The following is a collection of exercises based on computer vision fundamentals in PyTorch.\n",
        "\n",
        "They're a bunch of fun.\n",
        "\n",
        "You're going to get to write plenty of code!\n",
        "\n",
        "## Resources\n",
        "\n",
        "1. These exercises are based on [notebook 03 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/03_pytorch_computer_vision/).\n",
        "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/_PibmqpEyhA).\n",
        "  * **Note:** Going through these exercises took me just over 3 hours of solid coding, so you should expect around the same.\n",
        "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
      ],
      "metadata": {
        "id": "Vex99np2wFVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaeYzOTLwWh2",
        "outputId": "17dd5453-9639-4b01-aa18-7ddbfd5c3253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 16 03:23:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Exercises require PyTorch > 1.10.0\n",
        "print(torch.__version__)\n",
        "\n",
        "# TODO: Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "DNwZLMbCzJLk",
        "outputId": "ec1bf2b9-2a31-4ab9-faa9-2bffac374759"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. What are 3 areas in industry where computer vision is currently being used?"
      ],
      "metadata": {
        "id": "FSFX7tc1w-en"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Self driving cars (Tesla)\n",
        "2. Medical imaging analysis\n",
        "3. Face detection for security"
      ],
      "metadata": {
        "id": "M8ll4KS2NEci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find."
      ],
      "metadata": {
        "id": "oBK-WI6YxDYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting in machine learning is when a model learns the training data too well and performs poorly on unseen data."
      ],
      "metadata": {
        "id": "j2vO4CwbM_qp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Search \"ways to prevent overfitting in machine learning\", write down 3 of the things you find and a sentence about each.\n",
        "> **Note:** there are lots of these, so don't worry too much about all of them, just pick 3 and start with those."
      ],
      "metadata": {
        "id": "XeYFEqw8xK26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Data augmentation: Artificially increasing the size of the training dataset by creating modified versions of existing data.\n",
        "2. Early stopping: Monitoring the model's performance on a validation set and stopping training when the performance starts to decrease.\n",
        "3. Regularization: Adding a penalty term to the loss function to discourage the model from learning complex patterns."
      ],
      "metadata": {
        "id": "HaIO3kBzM2Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spend 20-minutes reading and clicking through the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/).\n",
        "\n",
        "* Upload your own example image using the \"upload\" button on the website and see what happens in each layer of a CNN as your image passes through it."
      ],
      "metadata": {
        "id": "DKdEEFEqxM-8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqZaJIRMbFtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load the [`torchvision.datasets.MNIST()`](https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST) train and test datasets."
      ],
      "metadata": {
        "id": "lvf-3pODxXYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets\n",
        "\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "SHjeuN81bHza"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "2pI4uObkNozK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training data\n",
        "train_data = datasets.MNIST(\n",
        "    root=\".\", # where to download data to?\n",
        "    train=True, # do we want the training dataset?\n",
        "    download=True, # do we want to download yes/no?\n",
        "    transform=transforms.ToTensor())  # how do we want to transform the data?\n",
        "\n",
        "\n",
        "test_data = datasets.MNIST(\n",
        "    root=\".\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuvQ6OkrNV7V",
        "outputId": "829aee46-87dc-491c-dc21-4ca6dc74d146"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17410147.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 479115.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4391954.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4343485.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2MWKCNWN8zZ",
        "outputId": "320011c6-eb62-4b16-b34f-576a0cd6b170"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: .\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " Dataset MNIST\n",
              "     Number of datapoints: 10000\n",
              "     Root location: .\n",
              "     Split: Test\n",
              "     StandardTransform\n",
              " Transform: ToTensor())"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See the first training example\n",
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTcjY1AHOGG5",
        "outputId": "7947f545-de35-47ab-ab46-a3259f5f33eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class names from the dataset\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFmDPW4cOkVS",
        "outputId": "c207df58-5f5e-4301-9cab-6d057b874b02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 - zero',\n",
              " '1 - one',\n",
              " '2 - two',\n",
              " '3 - three',\n",
              " '4 - four',\n",
              " '5 - five',\n",
              " '6 - six',\n",
              " '7 - seven',\n",
              " '8 - eight',\n",
              " '9 - nine']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Visualize at least 5 different samples of the MNIST training dataset."
      ],
      "metadata": {
        "id": "qxZW-uAbxe_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for i in range(5):\n",
        "  img = train_data[i][0]\n",
        "  print(img.shape)\n",
        "  img_squeeze = img.squeeze()\n",
        "  print(img_squeeze.shape)\n",
        "  label = train_data[i][1]\n",
        "  plt.figure(figsize=(3, 3))\n",
        "  plt.imshow(img_squeeze, cmap=\"gray\")\n",
        "  plt.title(label)\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "QVFsYi1PbItE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8044ee1d-8564-42b5-a6d6-bd8b9a0e3c1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAERCAYAAABSGLrIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAGKUlEQVR4nO3dK28UbRjH4WcaEkgQ5SQWDPsJoAZXgWhISRAoLHyBOpIaEgKKBEU42DZ4BEETwGwQeIqBNOGQEkRFFWLnla8hzywMu1v6vy57Dzu3+fGEzDLbtG3bFuBAW5j3AsD0CR0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCB0CCD3E3t5euX37dlldXS0nTpwoTdOUzc3Nea/FjAg9xI8fP8rdu3fL+/fvy/nz5+e9DjN2aN4LMBunT58u3759K4PBoLx7965cuHBh3isxQ070EIcPHy6DwWDeazAnQocAQocAQocAQocAQocAQocAQocAvjAT5NGjR2V3d7d8/fq1lFLKixcvyufPn0sppaytrZXFxcV5rscUNV73nGM4HJbt7e1fzj59+lSGw+FsF2JmhA4B/BsdAggdAggdAggdAggdAggdAggdAkz8zbimaaa5B/CHJvkqjBMdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAhya9wJkunXrVuc1d+7cqc4XFurn1MWLF6vzN2/edO5wUDjRIYDQIYDQIYDQIYDQIYDQIYDQIYDn6EzFjRs3qvP19fXOzxiPx712aNu2158/SJzoEEDoEEDoEEDoEEDoEEDoEEDoEEDoEMAXZpiKs2fPVudHjhyZ0SaU4kSHCEKHAEKHAEKHAEKHAEKHAEKHAJ6j80dWVlaq87W1td732Nraqs6vXLlSne/s7PTe4aBwokMAoUMAoUMAoUMAoUMAoUMAoUMAz9H5peXl5ep8Y2OjOl9cXOy9w/3796vz7e3t3vdI4USHAEKHAEKHAEKHAEKHAEKHAEKHAJ6j80vXr1+vzs+cOdPr81+/ft15zdOnT3vdg/850SGA0CGA0CGA0CGA0CGA0CGA0CGA0CFA07ZtO9GFTTPtXZiRU6dOdV7T9eMH4/G4Ot/d3a3Or1271rnDq1evOq+hlEkSdqJDAKFDAKFDAKFDAKFDAKFDAKFDAC+eOICGw2F1/uzZs6nv8PDhw+rcM/LZcqJDAKFDAKFDAKFDAKFDAKFDAKFDAM/RD6DV1dXq/Ny5c73v8fLly+r8wYMHve/B3+NEhwBChwBChwBChwBChwBChwBChwDe6/4Punr1anW+ublZnR89erTzHqPRqDrvei9713vh+Xu81x0opQgdIggdAggdAggdAggdAggdAggdAnjxxD60H36A4ePHj9W5L8T8W5zoEEDoEEDoEEDoEEDoEEDoEEDoEMBz9H1ofX29Oh+Px1Pf4d69e1O/B7PjRIcAQocAQocAQocAQocAQocAQocAnqPP2NLSUuc1ly5dmuoOz58/77zmw4cPU92B2XKiQwChQwChQwChQwChQwChQwChQ4CmneRX1EspTdNMe5cI379/77zm+PHjve7x9u3b6vzy5cudn7G3t9drB2ZnkoSd6BBA6BBA6BBA6BBA6BBA6BBA6BBA6BDAiydm7OTJk53X9P2BhidPnlTnvgyTx4kOAYQOAYQOAYQOAYQOAYQOAYQOATxH/8s2Njaq84WF6f/dOhqNpn4P/i1OdAggdAggdAggdAggdAggdAggdAjgOfpvWlpaqs5XVlaq80n+r/nPnz+r88ePH1fnOzs7nfcgixMdAggdAggdAggdAggdAggdAggdAniO/puOHTtWnQ8Gg973+PLlS3V+8+bN3vcgixMdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAnjxxG/a2tqqzkejUXW+vLz8N9eBiTjRIYDQIYDQIYDQIYDQIYDQIYDQIUDTtm070YVNM+1dgD8wScJOdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAggdAhwaNILJ/ydB2AfcqJDAKFDAKFDAKFDAKFDAKFDAKFDAKFDAKFDgP8AzUbb2RRpmrMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAERCAYAAABSGLrIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIoklEQVR4nO3dT4hVdR/H8e+YUIpJpAYSBVkpZLUpalE0G5uCIKIWtYjIWvQHgogokGhRumrVxk1CBRVlGIhuok05QU5WRAwaiUFQDjEgUYk14MyziRY9D7/f9Rlnrs3n9Vr6PZ37ZcZ3pzjn3jsyNzc3V8CStmzYCwALT+gQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOgQQOghvvzyy7rzzjtr9erVdeGFF9bY2Fh9/fXXw16LRTLiWfel76uvvqpbbrmlLrvssnrsscdqdna2du7cWSdOnKjPP/+8Nm3aNOwVWWBCD3DXXXfVZ599VkePHq01a9ZUVdXU1FRt3LixxsbGas+ePUPekIXmP90DjI+P15YtW/6OvKpq/fr1NTo6Wvv376/ff/99iNuxGIQe4M8//6wVK1b815+vXLmyZmZmanJycghbsZiEHmDTpk118ODBOn369N9/NjMzUxMTE1VV9dNPPw1rNRaJ0AM8+eST9d1339Wjjz5ahw8frsnJyXrooYdqamqqqqpOnTo15A1ZaEIP8Pjjj9e2bdvqnXfeqc2bN9d1111Xx44dq+eee66qqlatWjXkDVloQg+xY8eO+vnnn2t8fLy++eabOnToUM3OzlZV1caNG4e8HQvN7bVgN910U01NTdUPP/xQy5b5d/5S5rcb6r333qtDhw7V008/LfIArugBDhw4UC+99FKNjY3VmjVr6uDBg/X666/X7bffXvv27avly5cPe0UWmN9wgEsvvbTOO++8euWVV+q3336rK664orZv317PPPOMyEO4okMA/3MGAYQOAYQOAYQOAYQOAYQOAYQOAQZ+WmJkZGQh9wD+T4M8CuOKDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgGWD3sBztzNN9/cnD/44IPN+ejoaPc1Nm/efEY7/dOzzz7bnB8/frx7jltvvbU5f+utt5rziYmJ7mukcEWHAEKHAEKHAEKHAEKHAEKHAEKHACNzc3NzAx04MrLQu/CX+++/vzl/9dVXm/O1a9c254P8Lj/++OPmfN26dc35Nddc032Nnt6e77//fnP+wAMPzHuHf4NBEnZFhwBChwBChwBChwBChwBChwBChwDej36WLV/e/pHeeOON3XO89tprzfnKlSub8wMHDjTnL7/8cneHTz/9tDk///zzm/Pdu3c352NjY90der744ot5nyOFKzoEEDoEEDoEEDoEEDoEEDoEEDoEcB/9LOt9pvquXbvm/RofffRRc957P/uvv/467x16r3E27pP/+OOPzfmbb74579dI4YoOAYQOAYQOAYQOAYQOAYQOAYQOAYQOAXyBwxnqfWjDtm3bmvNBftw7d+5szl944YXm/Gw8ENNz5MiR5vzqq6+e92vcd999zfnevXvn/RpLgS9wAKpK6BBB6BBA6BBA6BBA6BBA6BDAB0/8w4svvtic9+6Tz8zMNOcffvhhd4fnn3++OT916lT3HC0XXHBB95jeB0dcfvnlzXnvuYvt27d3d3Cf/OxxRYcAQocAQocAQocAQocAQocAQocAUe9Hv+iii7rHfPvtt8352rVrm/P9+/c35/fcc093h/m66qqrmvO33367e44bbrhhXjvs2bOnOX/kkUe65zh58uS8dkjh/ehAVQkdIggdAggdAggdAggdAggdAkTdR7/kkku6xxw/fnxer7Fhw4bm/I8//uieY+vWrc353Xff3Zxfe+21zfmqVau6O/T+WvTm9957b3O+b9++7g4Mxn10oKqEDhGEDgGEDgGEDgGEDgGEDgGEDgGiHpgZ5IMnjhw50pyvW7euOe/9nAb8cc9L76GfQX6X69evb86np6fn9c9z9nhgBqgqoUMEoUMAoUMAoUMAoUMAoUOA5cNeYDH98ssv3WN6X7DQ+4KGiy++uDk/duxYd4e9e/c252+88UZzfuLEieb83Xff7e7Quw8+yDk4d7iiQwChQwChQwChQwChQwChQwChQ4Co++iDmJiYaM5770c/F9x2223N+ejoaPccs7Ozzfn3339/RjsxXK7oEEDoEEDoEEDoEEDoEEDoEEDoEMB99CVoxYoVzXnvHnlV/7PCvR/938UVHQIIHQIIHQIIHQIIHQIIHQIIHQIIHQKMzA3yLepVNTIystC7sEhOnz7dPab316L3BQ/T09NntBP/v0ESdkWHAEKHAEKHAEKHAEKHAEKHAEKHAD54Ygm64447hr0C5xhXdAggdAggdAggdAggdAggdAggdAjgPvoStGHDhmGvwDnGFR0CCB0CCB0CCB0CCB0CCB0CCB0CuI++BI2Pjzfny5b1//0+Ozt7ttbhHOCKDgGEDgGEDgGEDgGEDgGEDgGEDgGEDgE8MLMETU5ONudHjx7tnqP34RVXXnllcz49Pd19DRaPKzoEEDoEEDoEEDoEEDoEEDoEEDoEGJmbm5sb6MCRkYXehUXy8MMPd4/ZtWtXc/7JJ58050899VRzfvjw4e4ODGaQhF3RIYDQIYDQIYDQIYDQIYDQIYDQIYD76IFWr17dPWb37t3N+ZYtW5rzDz74oDnfunVrd4eTJ092j8F9dOAvQocAQocAQocAQocAQocAQocA7qPzP/Xute/YsaM5f+KJJ5rz66+/vruD96wPxn10oKqEDhGEDgGEDgGEDgGEDgGEDgGEDgE8MAP/ch6YAapK6BBB6BBA6BBA6BBA6BBA6BBg+aAHDni7HTgHuaJDAKFDAKFDAKFDAKFDAKFDAKFDAKFDAKFDgP8A1/7IbX4silEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Turn the MNIST train and test datasets into dataloaders using `torch.utils.data.DataLoader`, set the `batch_size=32`."
      ],
      "metadata": {
        "id": "JAPDzW0wxhi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup the batch size hyperparameter\n",
        "BATCH_SIZE = 32\n",
        "# Turn datasets into iterables (batches)\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "ALA6MPcFbJXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "562d4aac-2f93-4be6-d3a8-9c4c794f9b8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x793291c6b550>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x793291c6bcd0>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
      ],
      "metadata": {
        "id": "AE54cfz7QRTS",
        "outputId": "71f3d2e2-f44b-449c-a742-81968090d08d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x793291c6b550>, <torch.utils.data.dataloader.DataLoader object at 0x793291c6bcd0>)\n",
            "Length of train_dataloader: 1875 batches of 32...\n",
            "Length of test_dataloader: 313 batches of 32...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "id": "KSC65w1mQV-S",
        "outputId": "5df79dd4-e771-471d-c941-be9725e248d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "4yMNdBsOQhna",
        "outputId": "5a7a2042-7255-41d1-e92a-9d827aa20e45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Recreate `model_2` used in notebook 03 (the same model from the [CNN Explainer website](https://poloclub.github.io/cnn-explainer/), also known as TinyVGG) capable of fitting on the MNIST dataset."
      ],
      "metadata": {
        "id": "bCCVfXk5xjYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "w1Q8zWjORnIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a convolutional neural network\n",
        "class MNISTModelV2(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture that replicates the TinyVGG\n",
        "  model from CNN explainer website.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "             nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*7*7,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    # print(f\"Output shape of conv_block_1: {x.shape}\")\n",
        "    x = self.conv_block_2(x)\n",
        "    # print(f\"Output shape of conv_block_2: {x.shape}\")\n",
        "    x = self.classifier(x)\n",
        "    # print(f\"Output shape of classifier: {x.shape}\")\n",
        "    return x"
      ],
      "metadata": {
        "id": "5IKNF22XbKYS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_2 = MNISTModelV2(input_shape=1,\n",
        "                              hidden_units=10,\n",
        "                              output_shape=len(class_names)).to(device)"
      ],
      "metadata": {
        "id": "F83OJ3-MR0hS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2"
      ],
      "metadata": {
        "id": "itfNhzTSSSMS",
        "outputId": "82fa590a-17d6-4e94-b485-3343d3b77fc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MNISTModelV2(\n",
              "  (conv_block_1): Sequential(\n",
              "    (0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv_block_2): Sequential(\n",
              "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=490, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIzgMmfaSgPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor = torch.randn(size=(1, 28, 28)).unsqueeze(dim=0).to(device)\n",
        "rand_image_tensor.shape"
      ],
      "metadata": {
        "id": "GbqU5Yy9SALU",
        "outputId": "a329d728-86c6-4925-9383-b777fca1ea3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2(rand_image_tensor)"
      ],
      "metadata": {
        "id": "NqDJtz9JS5tc",
        "outputId": "d28c1b93-74b6-41ac-ed37-0f82d2fce41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0358, -0.0907,  0.0761, -0.0497,  0.0093,  0.0326,  0.0156, -0.0088,\n",
              "         -0.0064, -0.0145]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rand_image_tensor_2 = torch.rand(size=([1, 10, 7, 7]))\n",
        "rand_image_tensor_2.shape"
      ],
      "metadata": {
        "id": "S6I08AAbR8_D",
        "outputId": "39e00418-870b-411f-cac8-f0a02adc4d61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_layer = nn.Flatten()\n",
        "flatten_layer(rand_image_tensor_2).shape"
      ],
      "metadata": {
        "id": "rbYlqo4LTBYK",
        "outputId": "b1814d4e-334d-4691-a7ac-460713636b26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 490])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Train the model you built in exercise 8. for 5 epochs on CPU and GPU and see how long it takes on each."
      ],
      "metadata": {
        "id": "sf_3zUr7xlhy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jSo6vVWFbNLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediciton to the target label."
      ],
      "metadata": {
        "id": "w1CsHhPpxp1w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_YGgZvSobNxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Plot a confusion matrix comparing your model's predictions to the truth labels."
      ],
      "metadata": {
        "id": "qQwzqlBWxrpG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSrXiT_AbQ6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Create a random tensor of shape `[1, 3, 64, 64]` and pass it through a `nn.Conv2d()` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the `kernel_size` parameter goes up and down?"
      ],
      "metadata": {
        "id": "lj6bDhoWxt2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leCTsqtSbR5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Use a model similar to the trained `model_2` from notebook 03 to make predictions on the test [`torchvision.datasets.FashionMNIST`](https://pytorch.org/vision/main/generated/torchvision.datasets.FashionMNIST.html) dataset.\n",
        "* Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
        "* After visualing these predictions do you think it's more of a modelling error or a data error?\n",
        "* As in, could the model do better or are the labels of the data too close to each other (e.g. a \"Shirt\" label is too close to \"T-shirt/top\")?"
      ],
      "metadata": {
        "id": "VHS20cNTxwSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78a8LjtdbSZj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}